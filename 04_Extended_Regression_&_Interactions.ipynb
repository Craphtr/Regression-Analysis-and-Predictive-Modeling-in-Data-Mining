{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style = \"background-color: black\">\n",
    "    <p><b><font size=\"+4\" color=\"orange\">Other Issues in Regression</font></b></p>\n",
    "    <p><b><font size=\"+2\" color=\"white\">Extending the Linear Model</font></b></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data Manipulation Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS, summarize, poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Import Data Visualization packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "plt.rcParams.update({'font.size':12}) #sets global font size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block\" style=\"background-color: black\">\n",
    "    <p><b><font size=\"+2\" color=\"white\">Introduction</font></b></p>\n",
    "    </div>\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linear regression model works quite well by providing interepretable results on real-world problems but these results are based on restrictive assumptions that are often against the norm in practice. \n",
    "\n",
    "Two of these most common assumptions state the following that the relationship between the predictors and response are:\n",
    "\n",
    "* **Additive** - This implies that the association between a predictor variable and the response does not depend on the value of other predictors \n",
    "\n",
    "* **& Linear** - This implies that the change in the response caused by a unit-change in a predictor variable is constant regardless of the value of that predictor variable.\n",
    "\n",
    "Sophisticated techniques exist to address these two challenges and would be discussed in a different lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block\" style=\"background-color: black\">\n",
    "    <p><b><font size=\"+2\" color=\"orange\">1. Removing the Additive Assumption by adding an Interaction term</font></b></p>\n",
    "    </div>\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the Advertising-Sales problem, the linear models derived from the multiple linear regression model assumed that the effect of increasing one advertising medium (e.g TV) on sales does not affect the amount spent on the other type of media (e.g radio & newspaper). \n",
    "\n",
    "Considering the linear model used for the multiple linear regression:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sales = \\beta_{0} + \\beta_{1}TV + \\beta_{2}radio + \\beta_{3}newspaper + ∊ \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This model implies that the average increase in sales associated with one-unit increase in **TV** will always be $\\beta_{1}$ regardless of the amount spent on **radio** or **newspaper**. This simple model may be incorrect. Suppose spending money on radio advertising actually increases the effectiveness of TV advertising, so that the coefficient term for the TV increases as the radio increases. For instance, if given a fixed budget of $200,000, spending half on radio and half on TV may increase sales more than allocating the entire amount to either TV or radio. In statistics, this is called the **interaction effect**\n",
    "\n",
    "Interaction effect may be present in the advertising data, lets investigate this:\n",
    "Consider a standard linear regression model with two variables, $X_{1}$ & $X_{2}$:\n",
    "\n",
    "$$\n",
    "Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + ∈\n",
    "$$\n",
    "\n",
    "Lets try and understand what this model is telling us. According to this model, one-unit increase in $X_{1}$ leads to an average increase in Y by $\\beta_{1}$ units. The prescence of $X_{2}$ does not alter this statement regardless of the value of $X_{2}$. \n",
    "\n",
    "One way of sudying the inter-relatiionship between these predictor variables $X_{1} and X_{2}$ and the response variable $Y$ is by introducing an **interaction term**. This **interaction** term can be computed as the product of two predictor variables - $X_{1} and X_{2}$.\n",
    "\n",
    "$$\n",
    "Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}(X_{1} × X_{2}) + ∈\n",
    "$$\n",
    "\n",
    "Separating  this into $X_{1}$ and $X_{2}$ terms gives:\n",
    "\n",
    "$$\n",
    "Y = \\beta_{0} + (\\beta_{1}+\\beta_{3}X_{2})X_{1} + \\beta_{2}X_{2} + ∈\n",
    "$$\n",
    "\n",
    "So the new $\\beta_{1}$ term is $\\hat \\beta_{1} = \\beta_{1}+\\beta_{3}X_{2}$ which is now also a function of $X_{2}$. Hence the relationship between $X_{1} and Y$ is no longer a constant. A change in the value of $X_{2}$ will change the association between $X_{1}$ and $Y$\n",
    "\n",
    "**Let's now go back and reformulate the advertising problem with an interaction term between TV and radio advert budgets to predict sales** \n",
    "\n",
    "---\n",
    "## **Example - Multiple Linear Regression with interaction term**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sales = \\beta_{0} + \\beta_{1}TV + \\beta_{2}radio + \\beta_{3}(radio × TV) + ∊ \\\\\n",
    "= \\beta_{0} + (\\beta_{1} + \\beta_{3}radio)×TV + \\beta_{2}radio + ∊ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\beta_{3}$ can be interpreted as the increase in effectiveness of TV advertising associated with a unit increase in radio advertising (or vice-versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/ISLP_Data/Advertising.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-193396202984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAdvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/ISLP_Data/Advertising.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mAdvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/ISLP_Data/Advertising.csv'"
     ]
    }
   ],
   "source": [
    "Advert = pd.read_csv(\"../Data/ISLP_Data/Advertising.csv\")\n",
    "Advert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* State your independent,X and dependent variables,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({'TV':Advert['TV'],'Radio':Advert['radio'],'TV & Radio':Advert['TV']*Advert['radio']})\n",
    "Y = Advert['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the stats model to perform the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "MLR_interaction_TVRad = sm.OLS(Y,X).fit() #Perform the least squares fit\n",
    "predicted_MLR_interaction_TVRad = MLR_interaction_TVRad.predict(X) #retrieve your predicted Y values\n",
    "MLR_interaction_TVRad.summary() #Display your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's compare this with the model with no interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noint = pd.DataFrame({'TV':Advert['TV'],'Radio':Advert['radio']})\n",
    "X_noint = sm.add_constant(X_noint)\n",
    "MLR_no_interaction_TVRad = sm.OLS(Y,X_noint).fit() #Perform the least squares fit\n",
    "predicted_MLR_no_interaction_TVRad = MLR_no_interaction_TVRad.predict(X_noint) #retrieve your predicted Y values\n",
    "MLR_no_interaction_TVRad.summary() #Display your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis**\n",
    "\n",
    "The results presented above clearly show that the model which includes the interaction term is better and superior to the model with no interatcion term. \n",
    "* The p-value for the interaction term is extremely low, indicatiing that there's a strong evidence for the alternative hypothesis,H_{a}: $\\beta_{3}$. This proves to show that the true relationship is not additive.\n",
    "* The $R^{2}$ for the model is 96.8% compared to the model with no interaction term.\n",
    "* The effect of this interaction term is clearly evident in the increment in the $R_{2}$ value. A difference of (96.8 - 89.7) = 7.1%\n",
    "\n",
    "So therefore, if we increase TV advertising by 1000, sales will increase by $(\\hat \\beta_{1} + \\hat \\beta_{3} × radio)×1000 = 19 + 1.1 × radio$ where 19 & 1.1 are the coefficients multiplied by 1000.\n",
    "\n",
    "Likewise, if we increase radio advertising by 1000, sales will increase by: We rewrite the model by factoring out the radio units.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sales = \\beta_{0} + \\beta_{1}TV + \\beta_{2}radio + \\beta_{3}(radio × TV) + ∊ \\\\\n",
    "= \\beta_{0} + (\\beta_{1} + \\beta_{3}radio)TV + (\\beta_{2} + \\beta_{3}TV)radio + ∊ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This gives: $(\\beta_{2} + \\beta_{3}TV) × 1000 = 29 + 1.1$ × TV units.\n",
    "\n",
    "* The p-values associated with the 3 predictor variables -TV,radio and the interaction term are all statistically significant (very small). Hence, these 3 variables should be included in the model.\n",
    "\n",
    "But there may be the case where the interaction term may have a very small p-value but the associated main effects (i.e TV and radio) do not.\n",
    "\n",
    ">The guiding principle in this case is that *if we include an interaction in a model, we should also include the main effects, even if the p-values associated with their coefficients are not significant*\n",
    "**If the interaction between $X_{1}$ and $X_{2}$ seems important, then we should include both $X_{1}$ and $X_{2}$ in the model even if their coefficient estimates have large p-values**\n",
    "\n",
    "* The rationale for this guiding principle is that if $X_{1} × X_{2}$ is related to the response, then whether or not the coefficients of $X_{1} or X_{2}$ are exactly zero is of no importance.\n",
    "\n",
    "* Also, $X_{1} × X_{2}$ is typically correlated with $X_{1} and X_{2}$ and so leaving them out tends to alter the significance of the interaction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block\" style=\"background-color: black\">\n",
    "    <p><b><font size=\"+2\" color=\"orange\">1.1 Interaction between Quantitative &  Qualitative variables</font></b></p>\n",
    "    </div>\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example illustrated the interaction between two quantitative variables - TV and Radio. But the concept of interaction applies just as well to qualitative variables and the interaction between a qualitative and quantitative variable has an interesting interpretation. This will be illustrated using the **Credit** dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Illustration between Quantitative & Qualitative Variables with NO Interaction**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the Credit dataset, suppose we want to predict **balance** using the **income**(quantitative) and **student**(qualitative) variables in the abscence of an interaction term, the formulation of the model takes the form: \n",
    "\n",
    "* Create the dummy variable for student, $x_{i}$\n",
    "\n",
    "$$\n",
    "x_{i} =\n",
    "\\begin{cases}\n",
    "1 & \\mathit {\\text{if ith person is student}}\\\\\n",
    "0 & \\mathit {\\text{if ith person is not a student}}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This leads to the formulation of the linear regression model\n",
    "\n",
    "$$\n",
    "balance_{i} ≈ \\beta_{0} + \\beta_{1}income_{i} + \\beta_{2}x_{i} + ∈_{i} = \\beta_{1}Income_{i} + \n",
    "\\begin{cases}\n",
    "\\beta_{0} + \\beta_{2} + ∈_{i} & \\mathit{\\text{if the ith person is a student}}\\\\\n",
    "\\beta_{0} + ∈_{i} & \\mathit{\\text{if the ith person is not a student}}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "N.B: The final derived formulation for the linear regression above is the famous equation of a straight line $y = mx + c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credit = pd.read_csv('../Data/ISLP_DATA/Credit.csv')\n",
    "Credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create dummy variables for the student predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Student_Status= Credit.Student.str.get_dummies('No')\n",
    "Credit['Is_student_10'] = Student_Status\n",
    "Credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Regression directly from the formula created above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_Formula_Model_noint = sm.OLS.from_formula('Balance ~ Income + Is_student_10', Credit).fit()\n",
    "MLR_Formula_Model_noint.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(Credit.Income,Credit.Balance,marker='o',color='black')\n",
    "plt.plot(Credit.Income[Credit['Is_student_10']==1],MLR_Formula_Model_noint.fittedvalues[Credit['Is_student_10']==1],label='Student')\n",
    "plt.plot(Credit.Income[Credit['Is_student_10']==0],MLR_Formula_Model_noint.fittedvalues[Credit['Is_student_10']==0],label='Non-Student')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Balance');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analysis**\n",
    "\n",
    "From the plot above, we could observe two parallel regression lines fitted to the dataset. One for the students and one for non-students with intercepts $\\beta_{0} + \\beta_{2}$ and $\\beta_{0} respectively$. \n",
    "The parallelization of the regression lines means that the average increase in credit card balance caused by a unit increase in income does not depend on whether the individual is a student or not. This represents a potentially serious limitation of the model since in actual fact, a change in income may have a very different effect on the credit card balance of a student versus a non-student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Illustration between Quantitative & Qualitative Variables WITH Interaction**\n",
    "---\n",
    "\n",
    "The limitation observed above can be addressed by adding an interaction variable, created by multiplying income with the dummy variable for student. \n",
    "\n",
    "Remember the dummy variable is:\n",
    "$$\n",
    "x_{i} =\n",
    "\\begin{cases}\n",
    "1 & \\mathit {\\text{if ith person is student}}\\\\\n",
    "0 & \\mathit {\\text{if ith person is not a student}}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The model is then formulated thus:\n",
    "\n",
    "$$\n",
    "balance_{i} = \\beta_{0} + \\beta_{1}income_{i} + \\beta_{2}x_{i} + \\beta_{3}(income_{i}× x_{i}) + ∈ \\\\\n",
    "= \\beta_{0} + \\beta_{1}income_{i} +\n",
    "\\begin{cases}\n",
    "\\beta_{2} + \\beta_{3}× income_{i} & \\mathit {\\text{if student}}\\\\\n",
    "0 & \\mathit {\\text{if not student}}\n",
    "\\end{cases}\n",
    "$$ \n",
    "\n",
    "Separating out the terms into the two predictor variables - income and student dummy variable:\n",
    "\n",
    "$$\n",
    "balance_{i} = \n",
    "\\begin{cases}\n",
    "(\\beta_{0} + \\beta_{2}) + (\\beta_{1} + \\beta_{3}) × income_{i} & \\mathit {\\text{if student}}\\\\\n",
    "\\beta_{0} + \\beta{1} × income_{i} & \\mathit {\\text{if not student}}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Perform the Regression based on the formula stated above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_FormulaModel_w_int = sm.OLS.from_formula('Balance ~ Income + Is_student_10 + (Income * Is_student_10)',Credit).fit()\n",
    "MLR_FormulaModel_w_int.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=['student','non-student']\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(Credit.Income,Credit.Balance,marker='o',color='black')\n",
    "plt.plot(Credit.Income[Credit['Is_student_10']==1],MLR_FormulaModel_w_int.fittedvalues[Credit['Is_student_10']==1],label=label[0])\n",
    "plt.plot(Credit.Income[Credit['Is_student_10']==0],MLR_FormulaModel_w_int.fittedvalues[Credit['Is_student_10']==0],label=label[1])\n",
    "plt.title('Income vs Balance Relationship for Students & Non-Students with Interaction')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Balance');\n",
    "plt.legend()\n",
    "sb.lmplot(x=\"Income\",y=\"Balance\",hue=\"Student\",data=Credit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analysis**\n",
    "\n",
    "The plot above shows two regression lines again for the students and non-students. There is interaction between income and student\n",
    "\n",
    "* The regression lines have different intercepts $\\beta_{0} + \\beta_{2} = 200.6 + 6.2 = 206.8$ versus $\\beta_{0} = 200.6$ \n",
    "* and different slopes $\\beta_{1} + \\beta_{3} = 476.7 + (-1.99) = 474.7$ versus $\\beta_{1} = 476.7$\n",
    "\n",
    "This observation proves to show that changes in income could affect the credit card balances of students and non-students differently.\n",
    "The slope for students is lower than the slope for non-students suggesting that increases in income are associated with smaller increases in credit card balance among students as compared to non-students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block\" style=\"background-color: black\">\n",
    "    <p><b><font size=\"+2\" color=\"orange\">2. Non-Linearity via Polynomial Regression</font></b></p>\n",
    "    </div>\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, that the linear regression model assumes a linear relationship between the response and the predictor variables. But in actual fact, there may be cases whee the underlying relationship between the response and the predictors may be non-linear.\n",
    "\n",
    "In this section, we will extend the linear model to account for non-linear relationships using **polynomial regression** using the **Auto** dataset. We try to investigate the relationship between the horsepower of the vehicle against the miles per gallons used by that vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "Auto = pd.read_csv('../../../Data/ISLP_DATA/Auto.csv',na_values='?')\n",
    "Auto = Auto.dropna(0,'any')\n",
    "Auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get your Independent and dependedent variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = pd.DataFrame({'Horsepower':Auto['horsepower']})\n",
    "Y_1 = Auto['mpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make a scatter plot to explore the relationship between the two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Auto.plot.scatter('horsepower','mpg',marker='o',color='black',figsize=(7,4))\n",
    "ax.set_xlabel('Horsepower')\n",
    "ax.set_ylabel('Miles per gallon')\n",
    "ax.set_title('Relationship btw Horsepower & Mpg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a profund relationship between horsepower and miles per gallon but it is obvious that this relationship is infact non-linear. Rather than a constant declining slope between the two variables, we have a declining curve. We can account for this in our model.\n",
    "\n",
    "A simple approach for incorporating non-linear associations in a linear modelis to include **transformed versions** of the predictor variables. The shape of the declining curve above seems to be quadratic in shape, hence our linear model can be extended to a quadratic form.\n",
    "\n",
    "$$\n",
    "mpg = \\beta_{0} + \\beta_{1} × horsepower + \\beta_{2} × horsepower^{2} + ∈\n",
    "$$\n",
    "\n",
    "What this model is trying to achieve is to predict mpg using a non-linear function of horsepower. But it is still a linear model. It is a multiple linear regression model with predictor variable $X_{1} = horsepower$ and $X_{2} = horsepower^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Perform the Regression based on the relationship frmulated above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower2 = np.power(Auto.horsepower,2)\n",
    "MLR_NonLinearModel = sm.OLS.from_formula('mpg ~ horsepower + horsepower2 ',Auto).fit()\n",
    "ypred_deg2 = MLR_NonLinearModel.predict()\n",
    "print(summarize(MLR_NonLinearModel),\"\\n\\n\",\"Rsquared =\",MLR_NonLinearModel.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Perform the Regression to the 6th degree**\n",
    "\n",
    "We use a list comprehension to populate the columns of the polynomials of higher degrees till we get to the 5th degree. This makes our code less cumbersome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_PolyModel = sm.OLS.from_formula('mpg ~' + '+' .join(['np.power(horsepower,' + str(i) + ')' for i in range(1,7)]),Auto).fit()\n",
    "ypred_deg6 = MLR_PolyModel.predict()\n",
    "print(summarize(MLR_PolyModel),\"\\n\\n\",\"Rsquared =\",MLR_PolyModel.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Fit a linear model to the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_LinearModel = sm.OLS.from_formula('mpg ~ horsepower',Auto).fit()\n",
    "ypred_deg1 = MLR_LinearModel.predict()\n",
    "print(summarize(MLR_LinearModel),\"\\n\",\"Rsquared =\",MLR_LinearModel.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Plot the 3 Regression Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,7))\n",
    "plt.scatter(Auto.horsepower,Auto.mpg,marker='o',color=\"silver\")\n",
    "plt.scatter(Auto['horsepower'],ypred_deg1,label='linear')\n",
    "plt.scatter(Auto['horsepower'],ypred_deg2,label='2nd degree')\n",
    "plt.scatter(Auto['horsepower'],ypred_deg5,label='6th degree')\n",
    "plt.legend()\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('Miles per gallon')\n",
    "plt.title('Exploring Non-Linear relationship btw Horsepower & Mpg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis**\n",
    "\n",
    "Evaluating the three Models using the R-squared value, this measurement tells us how much of the total variance of the response - **miles per gallons** is explained by the model. The higher the R-squared, the better the model explains the data. It is clearly observed that as the number of features or predictor variables is increased, the R-squared value increases. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{array}{c c c}\n",
    " & R^{2} \\text{Values} & \\\\ \n",
    "Linear & \\text{2nd degree} & \\text{6th degree}\\\\\n",
    "0.606  & 0.688             & 0.696\n",
    "\\end{array} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The 6th degree polynomial displays a fit includes all polynomials up to the 6th degree with a minimal increase in the R-squared value compared to the 2nd degree poynomial. This questions the need for a higher-order polynomial to model the data. It is worth mentioning that the R-squared value will increase as the number of predictors are increased regardless of the importance or contribution each predictor does to the overall model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
